\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{float}
\usepackage{listings}
\usepackage{color}
\usepackage{bbm}
\title{Reinforcement Learning \\ Exercise 4 - Solution}
\author{Jonathan Schnitzler - st166934 \\
Eric Choquet - st160996}
\date{\today}
\begin{document}
\maketitle
\section*{Task 1)}


\paragraph*{a) Advantages of Monte Carlo over dynamic programming}

\begin{enumerate}
    \item Does not require knowlegde of the environment $p(s'| s,a)$ and $r(s,a,s')$.
    \item Simulate experience via simulator (or real world)
    \item every episode vs every state
\end{enumerate}

\paragraph*{b) Example for Monte Carlo to learn the value function (over DP)}

MC is preferable over DP when the distributions $p(s'|s, a)$ and $r(s,a,s')$ can not be sampled. For example, in blackjack it is not possible to sample them because they are up to chance.



\section*{Task 2)}

Programming task

The final result yields 


\end{document}